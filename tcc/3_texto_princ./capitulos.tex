\setlength\abovedisplayshortskip{0pt} \setlength\belowdisplayshortskip{0pt}

\chapter{Fundamentação Teórica} \label{cap1}
Neste capítulo são apresentados os conceitos
básicos e a fundamentação teórica necessária para o entendimento e abordagem do
problema do escalonamento de tripulações.

\section{Programação Linear}

A programação linear consiste na modelagem e solução de problemas descritos com
uma função objetivo linear sujeita a múltiplas restrições lineares. A forma
genérica de um problema de programação linear é, fornecida por~\cite{dantzig1955generalized}:

\begin{align} \label{funcao_obj} \text{maximizar} \: z &= \sum_{j=1}^{m}
    c_jx_j, \intertext{sujeito à:} \label{restricoes} \sum_{j=1}^{m} a_{ij} x_j
    \leq b_i, i &= 1, 2, \ldots, n \\ \label{restricoes_triviais} x_j \geq 0, j
    &= 1, 2, \ldots, m, \end{align}.

Onde $c_j, a_{ij}$ e $b_i$ são números reais que definem o problema e $x_j$
para $j=1, 2, \ldots, m$ são as variáveis de decisão. A
função~\eqref{funcao_obj} é denominada de função objetivo, a qual deve ser
maximizada. Note que o máximo de $f(x)$ é o mínimo de $-f(x)$ com o sinal
oposto max $f(x) = - \text{min} f(x)$. As inequações em~\eqref{restricoes}
representam um conjunto de $q$ restrições lineares que restringem o espaço de
busca para um poliedro convexo. O máximo da função deve estar contido dentro
deste poliedro. As desigualdades em~\eqref{restricoes_triviais} são denominadas
de restrições triviais ou de não negatividade.

Cada restrição em~\eqref{restricoes} pode ser convertida para restrição de
igualdade utilizando-se uma variável extra, denominada de variável de folga. A
utilização dá-se por:

\[ \label{restricoes} \sum_{j=1}^{m} a_{ij} x_j \leq b_i \Leftrightarrow
\begin{cases} \Sigma_{j=1}^{m} a_{ij} x_j + x_{m+i} = b_i\\ x_{m+i} \geq 0
\end{cases} \].

é possível ainda utilizar duas igualdades para representar uma igualdade:

\[ \label{restricoes} \sum_{j=1}^{m} a_{ij} x_j = b_i \Leftrightarrow
\begin{cases} \Sigma_{j=1}^{m} a_{ij} x_j \leq b_i\\ \Sigma_{j=1}^{m} a_{ij}
x_j \geq b_i \end{cases} \]

Para um problema qualquer de programação linear com restrições de desigualdades
e igualdades, sempre é possível reestruturá-lo através da adição de variáveis
de folga, para que o problema passe a ter apenas igualdades. Portanto, todo e
qualquer problema de programação linear pode ser expresso como:

\begin{align} \label{fo} \text{maximizar} \: z &= \sum_{j=1}^{n} c_jx_j
    \intertext{sujeito à:} \label{res} \sum_{j=1}^{n} a_{ij} x_j \leq b_i, i &=
    1, 2, \ldots, m \\ \label{res_t} x_j \geq 0, j &= 1, 2, \ldots, n
    \intertext{que é equivalente à:} \label{fo2} \text{maximizar} \: z &= cx
\intertext{sujeito à:} \label{res2} Ax &= b \\ \label{res_t2} x &\geq 0,
\end{align}.

Onde $c^T \in \mathbb{R}^n$, $x \in \mathbb{R}^n$, $b \in \mathbb{R}^m$, $A \in
\mathbb{R}^{m \times n}$ e $a_j \in \mathbb{R}^m$. Sendo que $c$ e $x$ são vetores de reais
de dimensão $n$, $b$ é um vetor de reais de dimensão $m$ e $A$ é uma matriz de dimensão $m \times n$
de valores reais.

Baseado nas restrições~\eqref{res2} e~\eqref{res_t2}, pode-se descrever o
problema como encontrar $x \in X$, onde $X = \{ x \in \mathbb{R}^n | Ax = b, x
\geq 0 \}$, tal que $cx$ seja maximizado. Ao conjunto $X$ dá-se o nome de
região factível ou espaço de busca. Para um $x \in X$ qualquer, diz-se que $x$
é uma solução factível.  Para um $x^* \in X$, se $cx^* \geq cx \forall x \in
X$, então $x^*$ é a solução ótima do problema. O espaço de busca para um
problema de programação linear é sempre um poliedro convexo, se interpretado
geometricamente, e a solução ótima para o mesmo sempre está em um vértice do
poliedro.

Um problema de programação linear pode ser ainda expresso em uma forma
matricial, ou em forma de conjunto. Suas representações são respectivamente:

\begin{align} \label{lp_fo} \text{maximizar} \: z &= cx \intertext{sujeito à:}
\label{lp_r} Ax &= b \\ \label{lp_tr} x &\geq 0 \intertext{} \label{lp_set}
\text{max } \{ cx : Ax &\leq b, x \geq 0 \} \end{align}

Com os modelos apresentados, pode-se modelar qualquer problema de otimização com
uma funções objetivo linear e sujeita a restrições lineares.

\subsection{Métodos de Solução}

Considerando o conjunto $X$ descrito na seção anterior, o objetivo de efetuar a
modelagem de um problema utilizando-se programação linear é utilizar recursos
matemáticos e algorítmicos para resolver o modelo, e por conseguinte o problema
original. Esta seção apresenta os três principais métodos encontrados na
literatura durante o desenvolvimento deste trabalho: o método simplex; o método
dos elipsoides; o método do ponto interior.

O método Simplex~\cite{dantzig1990origins} foi apresentado em 1947 por George
B. Dantzig com o objetivo de resolver o problema de programação linear. O
método consiste em encontrar uma solução factível ao problema, e iterativamente
mover para uma solução melhor ou igual que a atual. Considerando que a solução
está em um vértice do poliedro, é necessário apenas explorar os vértices. Tendo
em vista que existe um número finito de vértices para um poliedro descrito por
um conjunto finito de restrições lineares (que geometricamente correspondem a
hiperplanos), fica claro que o simplex converge em um número finito de passos.
Apesar de que na média o simplex resolve o problema em um número polinomial de
passos, em 1972 foi apresentado uma prova de que o método simplex no seu pior
caso é exponencial~\cite{klee1972good}.  Klee e Minty apresentaram um politopo
especialmente projetado para que o método simplex leve um número exponencial de
passos, o politopo é denominado de Cubo de Kleen-Minty.

Em decorrência da descoberta do cubo de Klee-Minty, diversos pesquisadores
iniciaram um estudo em busca de um método capaz de resolver o problema de
programação linear em tempo polinomial. Um dos primeiros trabalhos apresentados
na literatura propondo um algoritmo polinomial foi o método dos
elipsoides~\cite{khachian}. O método consiste em criar um elipsoide que englobe
a solução ótima e reduzi-lo sequencialmente de modo que a solução ótima sempre
esteja dentro do elipsoide. O método possui, em teoria, convergência garantida
em tempo polinomial. No entanto, na prática o método apresenta um desempenho
inferior ao simplex, como problemas de instabilidade numérica. O método
dos elipsoides demonstrou que diversos problemas podem ser resolvidos em tempo
polinomial~\cite{Grotschel1981}.

Em 1984 foi proposto um novo método polinomial para a solução do problema da
programação linear, denominado de método do ponto interior\cite{potra2000interior}.
Este método consiste em a partir de uma solução factível centro do politopo, perturba-la
até que a mesma convirja para o ponto ótimo. O método do ponto interior também é
referenciado na literatura como método das barreiras, já que as restrições
lineares são reescritas como funções assintóticas que tendem ao infinito quando
a restrição linear original é violada. O método do ponto interior apresentou um
desempenho comparável ao do simplex, e é especialmente aplicado em problemas de
larga escala.


\subsection{Dualidade}

Considerando o problema de programação linear apresentado
em~\eqref{funcao_obj},~\eqref{restricoes} e~\eqref{restricoes_triviais}, que a
partir de agora será denominado de problema primal,

\begin{align} \text{maximizar} \: z = \sum_{j=1}^{m} c_jx_j, \intertext{sujeito
a:} \label{rm} \sum_{j=1}^{m} a_{ij} x_j \leq b_i, i = 1, 2, \ldots, n \\
\label{} x_j \geq 0, j = 1, 2, \ldots, m, \end{align}.

O problema dual é construído atribuindo-se uma variável $u_i, i = 1, 2, \ldots,
q$ a cada restrição em~\eqref{rp} e definindo o problema como:

\begin{align} \text{minimizar} \: d = \sum_{i=1}^{n} b_iu_i, \intertext{sujeito
a:} \label{} \sum_{i=1}^{n} a_{ij} u_i \leq c_j, i = 1, 2, \ldots, m \\
\label{} u_i \geq 0, i = 1, 2, \ldots, n, \end{align}

O problema primal e dual em sua forma matricial são dados por:

\begin{align} \label{} \text{maximizar} \: z &= cx \intertext{sujeito à:}
    \label{prnt} Ax &= b \\ \label{prt} x &\geq 0, \intertext{e} \label{}
    \text{minimizar} \: d &= ub \intertext{sujeito à:} \label{drnt} uA^t &= c \\
    \label{drt} u &\geq 0,
\end{align}

À partir do problema primal e dual, conforme demonstrado
em~\cite{maculan2006otimizaccao}, segue que:

\begin{enumerate} \label{x} \item Se $\overline{x}$ satisfaz~\eqref{prnt}
        e~\eqref{prt} e $\overline{u}$ satisfaz~\eqref{drnt} e~\eqref{drt},
    então $c\overline{x} \leq \overline{u}b$; \item Se $\overline{x}$ e
        $\overline{u}$ forem \textbf{soluções factíveis} do problema primal e dual,
        respectivamente, e $c\overline{x} = \overline{u}b$, então
        $\overline{x}$ é a \textbf{solução ótima} do problema primal e $\overline{u}$ é
        a solução ótima do problema dual;
    \item Se $\tilde{x}$ é a \textbf{solução ótima} do problema primal e $\tilde{u}$ é a
        \textbf{solução ótima} do problema dual, então $c\tilde{x} = \tilde{u}b$.
\end{enumerate}

O primeiro item é conhecido como teorema da \textbf{dualidade fraca}, e sua implicação é
que uma solução dual é um limite superior de otimalidade para o problema
primal.  O segundo e terceiro item constituem o teorema da \textbf{dualidade forte}, que
pode ser utilizado para provar que uma solução de um problema primal é a ótima.

\section{Programação Linear Inteira}

A Programação Linear Inteira (PLI)~\cite{wolsey1998integer} trata de modelar problemas onde existem
variáveis inteiras. A forma genérica de um problema dá-se de forma análoga a de
um problema de programação linear:

\begin{align} \text{} \: z = \sum_{j=1}^{p} c_jx_j, \intertext{sujeito à:}
\label{} \sum_{j=1}^{p} a_{ij} x_j \leq b_i, i &= 1, 2, \ldots, q \\
\label{interg} x_j \geq 0 \text{ e } x_j \in \mathbb{Z}, j &= 1, 2, \ldots, p,
\end{align}

Nota-se que o modelo acima é exatamente igual a um problema genérico de
programação linear, exceto pela restrição em~\eqref{interg}, que faz com que os
valores de $x_j$ sejam inteiros. Esta restrição é denominada de restrição de
integralidade.

Outros problemas podem precisar de soluções que sejam inteiras e fracionárias, estes
problemas são denominados de problemas de programação linear mista (PLIM) e
possuem uma forma genérica de:

\begin{align} \text{} \: z = \sum_{j=1}^{p} c_jx_j, \intertext{sujeito à:}
    \label{plim_r} \sum_{j=1}^{p} a_{ij} x_j \leq b_i, i &= 1, 2, \ldots, q \\
    \label{plim_v} \sum_{j=1}^{r} g_{ij} y_j \leq d_i, i &= 1, 2, \ldots, q \\
    \label{} x_j \geq 0, j &= 1, 2, \ldots, p, \\ \label{plim_int} y_j \geq 0
\text{ e } y_j \in \mathbb{Z}, j &= 1, 2, \ldots, r \end{align}

A restrição~\eqref{plim_r} representa as variáveis fracionárias do modelo, a
restrição~\eqref{plim_v} as variáveis inteiras e~\eqref{plim_int} é a restrição
de integralidade.

Existem ainda problemas na qual é utilizado apenas variáveis binárias, a estes
problemas dá-se o nome de problema de programação linear inteira binária
(PLIB).  Eles possuem a forma genérica de:

\begin{align} \text{} \: z = \sum_{j=1}^{p} c_jx_j, \intertext{sujeito à:}
\label{} \sum_{j=1}^{p} a_{ij} x_j \leq b_i, i &= 1, 2, \ldots, q \\
\label{pbin} x_j \in \{0, 1\}, j &= 1, 2, \ldots, p, \end{align}

As restrições são iguais a de um problema de programação linear, exceto para a
restrição~\eqref{pbin}, que restringe o domínio das variáveis para valores de
$0$ ou $1$.

A PLI e suas variantes (PLIM e PLIB) são problemas $\mathcal{NP}$-completos,
conforme demonstrados por~\cite{karp1972} e~\cite{papadimitriou1981complexity}.
Sabe-se ainda que a PLI é um problema $\mathcal{NP}$-completo forte, portanto, é
improvável que exista um algoritmo pseudo-polinomial capaz de
resolvê-lo~\cite{garey1978strong}.

Considere o problema de PLI a seguir, em sua forma matricial:

\begin{equation} \label{pli_example} A = \begin{pmatrix} -1 &  2 \\ 5 &  1 \\
    -2 & -2 \end{pmatrix}, \quad b = \begin{pmatrix} 4 \\ 20 \\ -7
        \end{pmatrix}, \quad c^T = \begin{pmatrix} 1 \\ 1 \end{pmatrix}
\end{equation}

que corresponde ao seguinte problema de programação linear inteira:

\begin{subequations}
    \begin{align}
        \text{min} \: x_1 + x_2 \\
        -x_1 + 2x_2 = 4 \\
        5x_1 + x_2  = 20 \\
        -2x_1 + 2x_2 = -7
    \end{align}
\end{subequations}

\begin{figure}[!htb]
    \centering
    \begin{minipage}{.48\textwidth}
        \centering
        \begin{tabular}{r l}
            função objetivo & = $6.9090\ldots$ \\
            $x_1$           & = $3.2727\ldots$ \\
            $x_2$           & = $3.6363\ldots$
        \end{tabular}
        \captionof{table}{Solução da PLI}
        \label{rrrr}
    \end{minipage}
%
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[width=1\linewidth]{../figuras/pli.pdf}
        \caption{Espaço de busca do problema \eqref{pli_example}}
        \label{espacobusca}
    \end{minipage}
\end{figure}

Resolvendo-o obtém-se o resultado apresentado na Figura~\ref{rrrr}.
Considerando que o problema de PLI admite apenas variáveis com valores
inteiros, o resultado acima é inválido como resposta para o problema.
Observando-se a Figura~\ref{espacobusca}, que contém o espaço de busca do problema
em questão, pode-se observar que os pontos que são factíveis ao problema de PLI
são um subconjunto do espaço de busca de um problema de programação linear com
as mesmas restrições. Observa-se ainda que a solução ótima do problema de PLI
não coincide com a solução ótima do problema de programação linear. Portanto,
torna-se necessário a utilização de métodos específicos para resolver problemas de PLI.

\subsection{Relaxação Linear}

O conceito de relaxação no contexto de otimização corresponde a remover alguma
restrição do problema. O relaxamento de um problema tem como objetivo torná-lo
mais fácil de resolver. Dentre as diversas restrições que podem ser relaxadas, uma delas
é a restrição de integralidade, que se removida leva a uma relaxação linear.
Considerando que o problema de PLI genérico é $\mathcal{NP}$-completo, a
relaxação linear torná-lo um problema $\mathcal{P}$, que pode ser resolvido mais
rapidamente\cite{garey1978strong}.

Seja $x^*$ a solução ótima de um problema de maximização PLI e $\hat{x}^*$ a
solução ótima da relaxação do mesmo, segue que $x^* \leq \hat{x}^*$. Portanto a
relaxação linear é um limite superior de otimalidade para um problema de PLI
qualquer. O mesmo é válido para PLIM e PLIB.

O espaço de busca de um problema de PLI consiste em um conjunto de pontos com
coordenadas inteiras. A Figura~\ref{espacobusca} contém o conjunto de pontos
que satisfazem o problema original. O contorno que envolve os pontos consiste
na relaxação linear, onde a restrição de integralidade foi desconsiderada.
Pode-se notar que a área de busca aumentou e a solução ótima da relaxação é
maior do que o problema original.

\subsection{Relaxação Combinatória}

Para problemas combinatórios (discretos), a relaxação combinatória consiste em
remover uma ou mais restrições de um problema. Igualmente a relaxação linear, a
relaxação combinatória oferece um limite superior de otimalidade para um
problema de PLI, no entanto a relaxação combinatória não necessariamente torna
o problema mais fácil de se resolver, no sentido de diminuir a complexidade.

Um exemplo de relaxação combinatória é a remoção da restrição de \textit{sub-tours} no
problema do caixeiro viajante, que transforma-o em um problema de designação. O
problema de designação é um problema $\mathcal{P}$. Na prática utiliza-se esta
relaxação para resolver-se o problema do caixeiro
viajante~\cite{laporte1992traveling}.

\subsection{Métodos de solução de PLI}

Um dos primeiros métodos para solução de problemas de programação inteira foi
proposto por~\cite{gomory1960solving,gomory1960algorithm}. O método veio a ser
denominado de método de planos de cortes, que consiste em gerar hiperplanos
(restrições) que removem o ponto ótimo da relaxação linear sem remover o ótimo
da PLI. Esta sequencia de cortes faz com que a solução ótima da relaxação linear
seja a mesma do problema original.

Utilizando-se planos de corte pode-se
resolver problemas de PLI apenas com o SIMPLEX. O método funciona teoricamente,
porém na prática o método apresenta problemas de instabilidade numérica,
tornando-o inviável. Existem estudos que propuseram mudanças para viabilizar
o métodos~\cite{cook2009numerically}. \cite{zanette2011lexicography} apresenta
o uso do simplex lexicográfico para evitar a instabilidade numérica. Outro
plano de corte bem estabelecido na literatura é o corte por arredondamento
inteiro misto~\cite{wosley88}, que foi demonstrado ser uma forma genérica para
planos de cortes. Apesar de sua inviabilidade, os planos de corte possuem grande
importância teórica.

\cite{little1963algorithm} e
\cite{land2010automatic} propuseram um método de enumeração implícita que veio a
ser chamado de \textit{Branch and Bound}(BnB). O BnB consiste em dividir um
espaço de busca $S$ em subespaços $S_1, S_2, \ldots, S_n$ de modo que
$S_1 \cup S_2 \cup \ldots \cup S_n = S$. Para cada espaço gerado é calculado
um limite superior e inferior de otimalidade, e os espaços são divididos
novamente. Baseado nos limites, o BnB tende a seguir por regiões que levam
a melhores resultados e elimina regiões infrutíferas. Um exemplo de
limite superior é a relaxação linear, e um limite inferior é qualquer solução
factível para um problema. Se uma região $S_1$ possui um limite inferior de
$z = 22.4$ e uma região $s_2$ possui limite superior de $z = 21.0$, esta região pode
ser descartada desde que seja encontrado uma solução factível em $S_1$.
O desempenho do BnB está diretamente ligado à distância entre os limites inferiores
e superiores, quanto menor a distância melhor o desempenho tende a ser.

Uma das características dos planos de corte, é que eles podem reduzir a
distância entre a solução ótima da relaxação linear e a solução ótima
da PLI. Sendo assim, pode-se incluir a geração de planos de cortes no processo
de solução do BnB, melhorando assim seus limites. O BnB que utiliza planos de
cortes é denominado de \textit{Branch and Cut} (BnC).

\section{Problemas com Muitas Restrições ou Variáveis}

Na programação linear inteira existem problemas que tornam-se inviáveis de serem
resolvidos puramente com os métodos acima mencionados. Tomemos o problema
do caixeiro viajante(TSP)~\cite{dantzig1954solution} como exemplo. Em~\eqref{stsp} pode-se observar uma das
muitas possíveis modelagens para o problema do TSP. A restrição~\eqref{stsp3} é
o que difere o TSP de um problema de designação, e é o que torna o TSP um
problema $\mathcal{NP}$-difícil, pois esta restrição insere uma quantidade
fatorial de restrições no modelo do TSP. Em~\eqref{fat_tsp} temos uma fórmula
que descreve o número de restrições que~\eqref{stsp3} insere. Portanto,
é necessário que se utilize um procedimento denominado de geração de planos de cortes
para lidar com esta grandeza de restrições.

\begin{equation} \label{fat_tsp}
    \sum_{k=2}^{|A|-1} \binom{|A|}{k}!
\end{equation}


\begin{subequations}
    \label{stsp}
    \begin{align} \label{func_tsp2}
        z &= min \sum_{(i,j) \in A} c_{ij}x_{ij}
        \intertext{sujeito à:}
        & \sum_{i \in V}     x_{ij} =  1          & \forall    j \in V, i \neq j                   & \label{stsp1} \\
        & \sum_{j \in V}     x_{ij} =  1          & \forall    i \in V, i \neq j                   & \label{stsp2} \\
        & \sum_{(i,j) \in A} x_{ij} = |S|-1       & \forall \; S \subset V, 2 \leq |S| \leq |V|-1  & \label{stsp3} \\
        & 0 \leq x_{ij} \leq 1                    & \forall    (i,j) \in E                         &
    \end{align}
\end{subequations}

Considerando o modelo genérico de PLI~\eqref{glinhas} a seguir:

\begin{subequations} \label{glinhas}
    \begin{align} \label{}
        \text{maximizar} \: z &= cx
        \intertext{sujeito à:}
        \label{} Ax &= b \\
        \label{} x &\geq 0
    \end{align}
\end{subequations}

Pode-se escolher um conjunto arbitrário de restrições tal que
$\tilde{A} \subseteq A$ e $\tilde{b} \subseteq b$,
formando um novo problema de PLI~\eqref{glinhas2}.

\begin{subequations} \label{glinhas2}
    \begin{align} \label{}
        \text{maximizar} \: z &= cx
        \intertext{sujeito à:}
        \label{} \tilde{A}x &= \tilde{b} \\
        \label{} x &\geq 0
    \end{align}
\end{subequations}

Tem-se que~\eqref{glinhas2} é o problema apresentado em~\eqref{glinhas}, porém com um conjunto
reduzido de restrições, que pode ser resolvido mais facilmente. No entanto,
a solução ótima $\tilde{x}^*$ não necessariamente irá satisfazer
a~\eqref{glinhas}. Então é necessário que verifique-se qual das restrições
são violadas e estas devem ser inseridas em~\eqref{glinhas2}, que deve ser
resolvido novamente. Este verificação é conhecido como problema da separação,
que é $\mathcal{NP}$-completo, conforme demonstrado
em~\cite{nemhauser1988integer}.

O problema da separação pode ser formulado como outro problema de PLI, formulado de
modo dual, que indica qual é a restrição mais violada dentre todas. Esta
restrição é então adicionada ao problema, que é re-otimizado e pode ter
outras variáveis violadas. O processo é repetido até que não existam mais
variáveis violadas.

A principal vantagem deste método é que o conjunto de restrições finais é
muito menor do que o total de restrições do problema original. E portanto, o
custo de resolver diversos problemas de separação e efetuar múltiplas
re-otimizações do problema original mostrou-se ser mais rápido do que resolver
do que o problema original.

Existem ainda problemas onde o número de restrições é relativamente pequeno,
enquanto que o \textbf{número de variáveis é muito maior}. Um exemplo de problema com
este comportamento é o \textit{Cutting stock problem}~\cite{gilmore1961linear}. O problema consiste
em dado uma demanda de peças de tamanhos arbitrários e um estoque de peças de
tamanho fixo, determinar como cortar o estoque para obter as peças demandadas
com um desperdício mínimo. Sua formulação é dada a seguir:

\begin{subequations}\label{cuttingsp}
    \begin{align}
        z = min \sum_{j \in J} c_{j}x_{ij} \\
        \sum_{j \in J} a_{ij} x_j \geq b_j, \forall i \in I \\
        x_j \in \mathbb{Z}^+
    \end{align}
\end{subequations}

Onde $c_j$ corresponde a sobra de utilizar-se o corte $j$, $b_i$ é a demanda
para peças do tipo $i$, e $a_{j}$ corresponde a um padrão de corte.
Considere o seguinte exemplo: Deseja-se peças de tamanho $3, 4, \text{e } 5$
cortados a partir de um tubo de tamanho $10$. Alguns padrões válidos de corte
são: $(5, 5)$, $(5, 4)$, $(3, 3, 3)$, etc.

A matriz $A$ terá dimensões $m \times n$, onde $m$ é o número de diferentes
peças que são necessários e $n$ é o total de combinações de como se pode
efetuar os cortes. Conforme se aumenta o valor de $m$, $n$ cresce
exponencialmente.

Considerando que no simplex o número de variáveis básicas é limitado pelo
número de restrições, em um problema onde existe uma quantidade muito maior
de colunas do que linhas boa parte do tempo de solução seria gasto processando
variáveis que ao fim teriam o seu custo fixado em $0$. Portanto, a maioria
das colunas não são necessárias para obter-se o resultado final do problema.

A solução de problemas com muitas variáveis funciona de modo análogo ao com
muitas restrições. Com base no problema original, é formulado um novo problema,
denominado de problema mestre, que contém apenas um conjunto reduzido de colunas
do problema original. A relaxação do problema mestre é resolvido e obtém-se os
preços duais, que são utilizados para determinar quais colunas são necessárias
para resolver o problema até seu ponto ótimo. O problema auxiliar que é capaz
de determinar quais colunas são necessárias, é denominado de subproblema. No
capitulo~\ref{chap3} o problema mestre e o subproblema são apresentados
formalmente.

Utilizando-se a solução ótima $\tilde{x}^*$ do problema reduzido e sua solução
ótima dual $\tilde{y}^*$ pode-se testar $\tilde{y}^*$ por restrições violadas
no problema dual completo. Portanto, adicionar restrições no problema dual
corresponde a adicionar colunas (e variáveis) no problema primal. Este processo
de resolver o problema primal reduzido e detectar restrições duais pode ser
repetido até que se obtenha uma solução $\tilde{x}^*$ que não viole restrições
no problema dual.

De modo mais geral, pode-se apresentar o problema de geração de colunas conforme
exposto a seguir. Considere o problema genérico de PLI ~\eqref{k1},

\begin{subequations} \label{k1}
    \begin{align} \label{}
        \text{minimizar} \: z &\geq cx
        \intertext{sujeito à:}
        \label{} Ax &= b \\
        \label{} x &\geq 0
    \end{align}
\end{subequations}

no qual o número de variáveis é grande o suficiente para inviabilizar a inclusão
explicita de todas elas no modelo. Para contornar a inviabilidade gerada pelo
grande número de colunas, divide-se o problema original em vários subproblemas menores
e mais fáceis de resolver. Considere um novo problema de PLI~\eqref{k1}

\begin{subequations} \label{k2}
    \begin{align} \label{}
        \text{minimizar} \: z &\geq c\tilde{x}
        \intertext{sujeito à:}
        \label{} A\tilde{x} &= b \\
        \label{} \tilde{x} &\geq 0
    \end{align}
\end{subequations}

onde $\tilde{x} \subseteq x$. Ou seja,~\eqref{k2} é o problema \eqref{k1} com um
número reduzido de variáveis. Este novo problema, denominado de problema mestre, deve
ser testado para determinar a sua otimalidade em comparação ao problema original, com
o objetivo de obter-se a resista de~\eqref{k1} resolvendo-se o problema mais
fácil~\eqref{k2}. O teste de otimalidade pode ser feito resolvendo-se o problema da
separação do modelo dual do problema mestre, apresentado em~\eqref{k3}.

\begin{subequations} \label{k3}
    \begin{align} \label{}
        \text{maximizar} \: z &\leq by
        \intertext{sujeito à:}
        \label{} A^Ty &= c\label{kk3} \\
        \label{} c &\geq 0
    \end{align}
\end{subequations}

Resolvendo-se~\eqref{k3} e obtendo-se a solução primal $\tilde{x}$ e dual $\tilde{y}$.
Subentendo-se a solução dual a um teste que consiste em determinar todas as
restrições violadas por $\tilde{y}$ na restrição~\eqref{kk3}. As variáveis
referentes as restrições violadas são adicionas a~\eqref{k2}, modificando-se $A, b, c$
e $\tilde{x}$. Este processo é repetido até não haver mais restrições violadas no
problema dual.

O teste~\eqref{kk3} pode ser reescrito como $c-A^ty\geq0$. Isto mostra de forma mais clara
a equivalência do problema da separação no problema dual. Para cada variável $x_j$ o
termo $c$ em~\eqref{k4} corresponde ao seu custo reduzido no problema dual, calculado a partir
dos custos reduzidos no problema dual.

\begin{align} \label{k4}
    c - \sum_i a_{ij} y^*_i \geq 0
\end{align}

Percebe-se então que uma variável de custo reduzido negativo é equivalente a uma
restrição violada no problema dual. Esta variável, se adicionada ao problema mestre pode
gerar uma nova solução com um melhor valor na função objetivo, fazendo com que a
solução do problema mestre fique mais próxima da solução do problema original. Mesmo
que esta variável não seja incorporada na solução, ela altera os valores duais e faz com que
uma nova variável seja incorporada na próxima iteração do algoritmo.

Neste capitulo foi apresentado os principais conceitos teóricos necessários para
o entendimento do problema a ser abordado nos próximos capítulos deste trabalho.
Discutiu-se as principais representações de problemas de programação linear e
programação linear inteira, suas principais propriedades e métodos de solução.
Por fim introduziu-se o conceito de utilizar custo reduzido e o problema dual
para determinar restrições violadas ou colunas que podem melhorar a função objetivo.

\chapter{Escalonamento de Tripulação}
\label{chap3}

A alocação de tripulação (CSP) consiste em um dos principais problemas de planejamento
de operações dentro do contexto de empresas de transporte aéreo e terrestre.
Segundo reportado por~\cite{zeren2012improved}, os gastos com tripulação consistem
na segunda maior fonte de despesas, atrás apenas dos gastos de combustíveis. Portanto,
de um ponto de vista operacional pode-se utilizar métodos de otimização para oferecer
reduções significativas nos gastos, enquanto que de um ponto de vista acadêmico é um
problema difícil de resolver, com grandes instâncias e uma aplicabilidade prática.

O CSP designa jornadas para um conjunto de tripulantes de
modo a cobrir todas as tarefas que devem ser realizadas. Conforme já definido no
capítulo~\ref{cap1}, uma \textbf{tarefa} é definida como sendo uma ação que deve
ser realizada por uma tripulação. Durante uma tarefa a tripulação dedica-se integralmente
a mesma durante um período de tempo fixo. Uma \textbf{jornada} consiste em um conjuntos de
tarefas que dever ser cobertas por uma tripulação. A cada jornada é atribuído um
custo operacional, e a geração de jornadas esta limitada por leis trabalhistas e
sindicais. O principal objetivo do CSP é determinar o conjunto de jornadas que
cobre todas as tarefas, reduzindo o custo operacional, respeitando as restrições
impostas em relação as jornadas de trabalho e designando apenas uma tripulação
por jornada.

Conhecendo-se um número suficientemente grande de jornadas (grande o suficiente
para poder cobrir todas as tarefas de modo factível) pode-se modelar o CSP como
um problema de \textit{set covering problem} (SCP, ou do português, problema de cobertura de conjuntos)
ou \textit{set partitioning problem} (SPP, do português, problema de particionamento de conjuntos),
dependendo se é desejável que uma jornada seja coberta mais de uma vez. No restante
deste capitulo é discutido os problemas de cobertura e particionamento assim como uma
abordagem mais detalhada do CSP.

\section{Modelagem do Problema}
\label{csppppp}

Esta seção é dedicada a explicar a modelagem e as instâncias utilizadas neste
trabalho. Utilizou-se as instâncias presentes na \textit{OR-Library}~\cite{beasley1990or},
apresentadas inicialmente em~\cite{beasley1996tree}. Este trabalho utiliza a versão
de Junho de 2016 das instâncias.

Na \textit{OR-Library} existem 10 problemas de CSP presentes, sendo que todos
eles são utilizados como objeto de estudo neste trabalho. Cada instância é apresentada
no seguinte formato: Número de tarefas($N$); Tempo limite de uma jornada; para cada
$i\text{ em }\{1, \ldots, N\}$: tempo de início, tempo de termino; Para cada par
$(i, j)$ de arestas, onde $j$ começa após o término de $i$, o custo da transição
de $i$ para $j$. O problema pode ser representado em um grafo, conforme visto na Figura~\ref{fig_graph_csp}
Beasley, no seu artigo considera um número fixo de jornadas para a solução final.
Este número fixo corresponderia a tripulação disponível operar. Apesar desta informação
não estar disponível nas instâncias, ela foi utilizada.

{
    \centering
    \includegraphics[width=0.5\linewidth]{../figuras/graph.pdf}
    \captionof{figure}{Jornadas modeladas como grafo}
    \label{fig_graph_csp}
}

As instâncias apresentadas podem ser formuladas matematicamente de diversas maneiras.
Uma delas é apresentada no artigo onde foram propostas as instâncias. Neste trabalho utilizou-se
uma formulação baseada em particionamento de conjuntos. Para que se possa obter a
resposta ótima para qualquer instância de CSP modelada como SPP, o modo mais simples de modelar consiste
em enumerar todas as jornadas viáveis. Algo que é impraticável, considerando
que o fato de enumerar-se todas as jornadas leva um tempo exponencial em relação ao
número de tarefas. No entanto este modelo é a base para a solução por geração de colunas.

%\begin{figure}[!htb]
%{
%}
%\end{figure}

Na Figura~\ref{fig_graph_csp} é apresentado um grafo relativo a instância apresentada
na tabela~\ref{tab_graph_csp}, no modelo apresentado acima. A enumeração de todas as jornadas
factíveis e seus respectivos custo e durações são apresentadas na tabela~\ref{tab_gragh_csp_enum}.
Utilizando-se estas informações, é possível utilizar um problema de particionamento de conjuntos
para resolver o CSP. A formulação genéria de um SPP é apresentada em~\eqref{spppp}. Tem-se que $c_j$
é o custo associado a $j$-ésima jornada, $x_j = 1$ se e somente se a jornada $j$ é utilizada. Tem-se
ainda que $a_{ij} = 1$ se e somente se a $i$-ésima tarefa é coberta pela $j$-ésima jornada.
Em~\eqref{csp_1} tem-se a codificação para uma PLI do SPP associado ao problema de CSP apresentado
na tabela~\ref{tab_graph_csp}. A função objetivo~\eqref{spp2} consiste no produto escalar entre o vetor de custos
de cada jornada e as variáveis de decisão $x$. A restrição~\eqref{spp22} faz com que cada tarefa seja coberta
exatamente uma única vez. A restrição~\eqref{spp23} faz com que sejam utilizadas exatamente duas jornadas para
cobrir as tarefas existentes.

%\begin{table}[htpb!]
{
    \centering
    \begin{minipage}{.5\textwidth}
        \centering
        \begin{tabular}{c c c}
            5  & 14 &   \\% \hline
            1  & 7  &   \\% \hline
            1  & 4  &   \\% \hline
            11 & 14 &   \\% \hline
            6  & 10 &   \\% \hline
            11 & 15 &   \\% \hline
            1  & 3  & 5 \\% \hline
            1  & 5  & 6 \\% \hline
            2  & 3  & 3 \\% \hline
            2  & 4  & 4 \\% \hline
            2  & 5  & 6 \\% \hline
            4  & 3  & 4 \\% \hline
            4  & 5  & 3 \\% \hline
        \end{tabular}
        \captionof{table}{Instância do CSP}
        \label{tab_graph_csp}
    \end{minipage}%
    \begin{minipage}{0.5\textwidth}
        \centering
        \begin{tabular}{l l l}
            Jornada                           & Custo & Duração \\
            1 $\rightarrow$ 3                 & 5     & 13 \\
            1 $\rightarrow$ 5                 & 6     & 14 \\
            2 $\rightarrow$ 3                 & 3     & 13 \\
            2 $\rightarrow$ 4                 & 4     & 9  \\
            2 $\rightarrow$ 4 $\rightarrow$ 5 & 7     & 14 \\
            2 $\rightarrow$ 4 $\rightarrow$ 3 & 8     & 13 \\
            2 $\rightarrow$ 5                 & 6     & 14 \\
        \end{tabular}
        \captionof{table}{Enumeração de todas as jornadas viáveis}
        \label{tab_gragh_csp_enum}
    \end{minipage}
}
%\end{table}

Resolvendo-se o problema apresentado em~\eqref{csp_1} e~\eqref{spppp} com um método de \textit{branch and bound},
obtém-se a solução ótima composta por: Uma jornada que cobre as tarefas $1$ e $3$; Uma jornada que cobre as tarefas $2$, $4$ e $5$.
A resolução desta instância ocorre praticamente instantaneamente, no entanto, ao aumentar-se os tamanhos das instâncias,
a resolução utilizando-se métodos tradicionais (BnB, BnC) de PLI torná-se inviável e uma outra estratégia deve ser empregada.
~\cite{desrochers1989column} utiliza uma abordagem de geração de colunas utilizando o problema de cobertura para modelar o CSP.~\cite{beasley1996tree}
utiliza relaxação lagrangiana com otimização de sub gradientes em conjunto com uma busca em árvore.~\cite{smith1988bus} utilizou
diversos modelos matemáticos para tentar acelerar o processo de solução utilizando o IMPACS~\cite{smith1988impacs}.
Algumas abordagens heurísticas para o problema incluem~\cite{doalgoritmos} e~\cite{silva2002simulated}.~\cite{Bergh}
e~\cite{ernst2004staff} oferecem um \textit{survey} detalhado da área.

\begin{subequations}
    \label{spppp}
    \begin{align}
        \label{spp2}  \text{min} \: \sum_{j \in J} c_j x_j \\
        \label{spp22} \sum_{j \in J} a_{tj} x_j = 1, \forall t \in T \\
        \label{spp23} \sum_{j \in J}        x_j = 2 \\
        \label{spp24} x_j \in \{0, 1\}, \forall j \in J
    \end{align}
\end{subequations}

\begin{equation}
    \label{csp_1}
    A = \begin{pmatrix}
        1 & 1 & 0 & 0 & 0 & 0 & 0 \\
        0 & 0 & 1 & 1 & 1 & 1 & 1 \\
        1 & 0 & 1 & 0 & 0 & 1 & 0 \\
        0 & 0 & 0 & 1 & 1 & 1 & 0 \\
        0 & 1 & 0 & 0 & 1 & 0 & 1 \\
    \end{pmatrix}, \quad
    b = \begin{pmatrix}
        1 \\
        1 \\
        1 \\
        1 \\
        1 \\
    \end{pmatrix}, \quad
    c^T = \begin{pmatrix}
        5 \\
        6 \\
        3 \\
        4 \\
        7 \\
        8 \\
        6 \\
    \end{pmatrix}
\end{equation}

No trabalho de~\cite{dos2008metodo}, o autor apresenta uma tabela contendo 5 instâncias reais
do problema de CSP e o seu respectivo número de jornadas viáveis. Esta tabela está reproduzida
na tabela~\ref{tab_iters}. Como se pode observar, o número de jornadas viáveis é grande mesmo
para um número relativamente pequeno de jornadas. No caso da tabela considera-se apenas uma linha
de ônibus, o que consiste em uma versão mais simples do problema.

\begin{table}[htpb]
    \centering
    \begin{tabular}{l l l}
        Itinerário & Número de tarefas & Jornadas viáveis \\
        101        & 40                & 1037190          \\
        201        & 49                & >4000000         \\
        321        & 54                & >4000000         \\
        1170       & 54                & 292505           \\
        2153       & 43                & 10045            \\
    \end{tabular}
    \caption{Jornadas das intâncias utilizadas em~\cite{dos2008metodo}}
    \label{tab_iters}
\end{table}

Dentre todas as possíveis jornadas possíveis para uma instância qualquer de CSP, apenas um
número relativamente pequeno é utilizado de fato. Considerando por exemplo o Itinerário 101
da tabela~\ref{tab_iters}, tem-se 1037190 jornadas, sendo que no máximo 40 podem ser utilizadas (assumindo
que cada jornada cubra o mínimo possível), na pratica utilizou-se apenas 3 jornadas.
Isto ocorre pelo fato de que a grande maioria das jornadas
é de custo muito alto ou não cobre um número suficiente de tarefas para valer a pena ser considerada.
Não obstante, para garantir-se que a solução encontrada é ótima, deve-se considerar integralmente o conjunto
de jornadas possíveis, mesmo que de modo implícito. Na seção a seguir é apresentado um modelo baseado em geração
de colunas, capaz de resolver o CSP de modo exato, obtendo a solução ótima. O algoritmo considera
as jornadas de modo explícito, isto é, as jornadas não são pré-calculadas.

%Com o exposto acima concluímos que

\section{Geração de Colunas para o CSP}

Conforme visto na seção\ref{csppppp}, considerar explicitamente o conjunto de todas as jornadas possíveis para
uma instância de CSP é algo que pode inviabilizar a solução do problema. Um método que contorna
este problema é o de geração de colunas~\cite{desaulniers2006column}~\cite{barnhart1998branch}.

%\begin{figure}[!htb]
%\begin{minipage}
{
    \centering
    \includegraphics[width=0.8\linewidth]{../figuras/gercolumn.pdf}
    \captionof{figure}{Processo de geração de colunas}
    \label{treta}
}
%\end{minipage}
%\end{figure}

O método de geração de colunas é decomposto em dois problemas menores: Problema mestre, o problema a ser resolvido;
Sub problema, que é um modelo de PLI capaz de identificar que informação é necessária para que o problema
mestre encontre a solução ótima.

A interação entre os dois problemas é mostrada na Figura~\ref{treta}. A relaxação linear do problema mestre é resolvido com um
conjunto inicial de jornadas, de modo que o problema possua uma solução factível. A partir da solução da relaxação do
problema mestre obtém-se os preços duais associados às restrições do problema, que são utilizados na formulação do subproblema.
O subproblema então utiliza os preços duais para calcular uma nova jornada que tem a possibilidade de contribuir para o problema
mestre. Esta nova jornada é adicionada no problema mestre e o processo repete-se. A condição de parada consiste
no problema mestre obter uma solução com custo reduzido negativo, o que indica que não é possível melhorar o problema mestre.
O problema mestre até o presente momento foi resolvido sob o efeito de uma relaxação linear. Portanto, caso existam
variáveis não inteiras é necessário resolver o problema mestre mais uma vez, desta vez utilizando-se um método de solução para
PLI.

Nas seções a seguir é discutido formalmente a formulação e funcionamento do processo de geração de colunas.

\subsection{Problema Mestre}

O problema mestre deve ser capaz de obter uma solução factível e ótima para o problema original. Quando aplicado
ao CSP, o problema mestre consiste de um SPP. Tem-se que cada coluna corresponde a uma jornada viável, com uma
variável e um custo associado. Cada linha esta representando uma tarefa que deve ser coberta por exatamente
uma jornada.

Como o SPP é um problema de PLI, ele não possuí a propriedade de dualidade forte, fazendo com que
a solução dual associada não possua o mesmo valor da função objetivo. Portanto, o calculo dos preços duais
de modo correto é inviabilizado. Sendo assim utiliza-se a relaxação linear do problema mestre, que possui
a propriedade de integralidade forte. No caso da relaxação linear, as variáveis deixam de ser inteiras (ou binárias)
e passam a ser não negativas. Considerando que na formulação do problema mestre tem-se a restrição de cobertura, que faz
com que o somatório das variáveis de cobertura de uma tarefa sejam iguais à $1$ e existe a restrição de não negatividade
das variáveis, as variáveis tem automaticamente o seu valor limitado entre $0$ e $1$.

Considerando-se as instâncias da \textit{OR-Library}, o problema mestre é dado em~\eqref{pmaster}. Note que $J$ é o conjunto
de todas as jornadas factíveis, e que o modelo utiliza $\tilde{J}$, sendo que $\tilde{J} \subset J$. A constante $NJ$ corresponde
ao tamanho da tripulação, que é fixo e conhecido \textit{à priori}. O restante da formulação~\eqref{pmaster} é igual à~\eqref{spppp}.

\begin{subequations}
    \label{pmaster}
    \begin{align}
        \label{pmaster1}  \text{min} \: \sum_{j \in \tilde{J}} c_j x_j \\
        \label{pmaster2} \sum_{j \in \tilde{J}} a_{tj} x_j = 1, \forall t \in T \\
        \label{pmaster3} \sum_{j \in \tilde{J}}        x_j = NJ \\
        \label{pmaster4} x_j \geq 0, \forall j \in \tilde{J}
    \end{align}
\end{subequations}

Uma questão a se considerar em relação ao problema mestre, é a necessidade de uma solução factível no \textquote{Inicio} do processo.
No caso do SPP, deve ter um conjunto de colunas (jornadas) que possam cobrir todas as tarefas.

A partir da solução do problema mestre, obtém-se um conjunto de informações relativos aos preços duais.  Considerando que cada
restrição esta associada a uma tarefa, o custo reduzido da restrição quantifica quanto que uma jornada que cubra a tarefa associada
pode melhorar a solução do SPP. Note que a restrição~\eqref{pmaster3} não esta associada a uma tarefa em específico, mas sim ao
número de jornadas que podem ser utilizadas simultaneamente. O vetor de comprimento $|T|$, onde $T$ é o conjunto de todas as
tarefas, que contém o custo reduzido das restrições é referenciado neste trabalho como $\tilde{\pi}$, onde $\tilde{\pi}_t$ indica
o custo reduzido associado a tarefa $t$. O custo reduzido de~\eqref{pmaster3} é referenciado como $\tilde{\mu}$.

Uma, jornada gerada pelo subproblema, por si só pode ser ótima para um dado conjunto de custos reduzidos,
mas em conjunto com as demais jornadas presentes no problema mestre pode não levar a solução ótima. A importância
de $\tilde{\mu}$ está em determinar se é possível encontrar uma melhor solução utilizando jornadas sub ótimas.
Os preços duais $\tilde{\mu}$ e $\tilde{\pi}$ são utilizados no subproblema para identificar quais
colunas devem ser geradas, conforme é exposto na seção a seguir.

\subsection{Subproblema}
\label{sec_subp}

O problema mestre possui a funcionalidade de escolher quais jornadas devem ser utilizadas, já o subproblema é responsável
por produzir novas jornadas para o problema mestre e indicar quanto a solução é ótima. O subproblema gera novas colunas
enquanto sua função objetivo for negativa.

Uma jornada consiste em uma sequencia de tarefas, onde a transição entre cada tarefa possui um custo. Sendo assim, uma
jornada deve minimizar o custo, e o conjunto de todas as jornadas deve ser capaz de cobrir todas as tarefas. No entanto,
existe um limite de tempo para cada jornada, portanto, o caminho mínimo esta restrito. Este problema é denominado de
caminho mínimo com restrições, e é um problema $\mathbb{NP}$-completo~\cite{irnich2005shortest}.

A formulação do subproblema dá-se em~\eqref{subp}. O subproblema é modelado como sendo um grafo. Neste grafo, cada arco
$a = (v_t, v_w)$ possui um custo $c_a$ que representa o custo de transição entre $t$ e $w$. Existem ainda dois nós
fictícios para facilitar a modelagem: $v_0$ e $v_f$. O nó $v_0$ conecta a todos os outros nós (exceto $v_f$), o nó
$v_f$ possui todos os nós levando a ele. Todos os arcos que conectam $v_0$ e $v_f$ possuem custo $0$. A constante $MaxW$
representa a duração máxima de uma jornada. O valor de $d_a$ é a duração do arco de transição somado com a
duração do nó final (da transição).

A variável de decisão $y_a$ possuem seu valor igual a $1$ se e somente se o arco $a$ é utilizado na jornada. A variável de
decisão $v_t$ vale $1$ se e somente se o vértice associado a tarefa $t$ esta presente na jornada. Em um problema simples
de caminho mínimo apenas o uso da variável de decisão $y_a$ é o suficiente. No entanto, para o CSP a variável de
decisão $v_t$ possuí a funcionalidade de guiar a função objetivo utilizando os custos reduzidos oriundos do problema mestre.

\begin{subequations}
    \label{subp}
    \begin{align}
        \label{subp1} \text{min} \: \sum_{a \in A} c_a y_a - \sum_{t \int T} \tilde{\pi}_t v_t - \tilde{\mu}\\
        \label{subp2} \sum_{a \in \delta^{+} (v_0)} y_{a} = \sum_{a \in \delta^{-} (v_f)} y_{a} = 1 \\
        \label{subp3} \sum_{a \in \delta^{+} (v_t)} y_{a} = \sum_{a \in \delta^{-} (v_t)} y_{a} = v_t, \forall t \in T \\
        \label{subp4} \sum_{a \in A} d_a y_{a} \leq MaxW \\
        \label{subp5} v_t, y_a \in \{0, 1\}, \forall v_j \in V, \forall a \in A
    \end{align}
\end{subequations}

A função objetivo~\eqref{subp1} possui $3$ elementos: $\sum_{a \in A} c_a y_a$ é componente que guia a função objetivo
em direção ao caminho de menor custo; $- \sum_{t \int T} \tilde{\pi}_t v_t$ é responsável por guiar o processo de solução
a escolher um caminho que contenha as tarefas que tenham o potencial de melhorar a solução do problema mestre; por fim $- \tilde{\mu}$
possui a finalidade de possibilitar que a geração de colunas crie jornadas sub ótimas, que no contexto geral podem levar
a solução ótima.

A restrição~\eqref{subp2} faz com que exatamente um arco saia do nó inicial e um arco chegue no nó inicial.
A restrição~\eqref{subp3} garante que o número de arcos que conectam a um nó é o mesmo que o número de arcos que conectam
este nós a um outro. Esta restrição ainda faz com que número de arcos incidentes seja o mesmo que o valor da variável $v_t$.
A restrição~\eqref{subp5} faz com que $v_t$ tenha seu valor restrito em $0$ ou $1$, portanto o grau de incidência para qualquer
nó (exceto $v_0$ e $v_t$) é zero ou um. A não ser pela presença da variável $v_t$. Por fim, a restrição~\eqref{subp4} faz
com que as jornadas tenham no máximo uma duração pré definida.

%solv_subp\begin{figure}[!htb]
{
\centering
\begin{minipage}{0.48\textwidth}
    \centering
        \includegraphics[width=1\linewidth]{../figuras/graph2.pdf}
        \captionof{figure}{Exemplo do subproblema}
        \label{graph2}
\end{minipage}
%
\begin{minipage}{0.48\textwidth}
    \centering
    \begin{tabular}{r c l | r c l}
        $v_1$ &=& $6$  & $v_{(1,2)}$ &=& 1\\
        $v_2$ &=& $7$  & $v_{(1,3)}$ &=& 6\\
        $v_3$ &=& $4$  & $v_{(2,3)}$ &=& 2\\
    \end{tabular}
    \captionof{table}{Preços Duais e custos}
    \label{tab_pd}
\end{minipage}
}
%\end{figure}

Considere o grafo na Figura~\ref{graph2} como um subproblema, na qual os preços duais e os custos
das arestas são apresentados na tabela~\ref{tab_pd}. As arestas tracejadas fazem parte do grafo, porém
não fazem parte da solução encontrada. As arestas em destaque formam uma solução de custo reduzido
negativo para o subproblema. Tem-se então que $y_{(0,1)} = y_{(1,3)} = y_{(3,f)} = 1$ e os demais
$y_{(i,j)} = 0$, já para os vértices tem-se $v_1 = v_3 = 1$ e $v_2 = 0$. Portanto obtêm-se uma
função objetivo onde o primeiro termo possui um valor de $y{(1,3)}\cdot6 = 6$ e o segundo vale
$v_1 \cdot 6 + v_3\cdot4 = 10$, resultando em $-4$.

Neste capitulo discutiu-se a modelagem do SPP e do CSP. Discutiu-se ainda como são modelados o problema mestre utilizando SPP
e o subproblema utilizando caminho mínimo com restrições.

\chapter{Proposta}

Nos capítulos anteriores discutiu-se a fundamentação teórica da PLI, bem como os detalhes de modelagem do CSP utilizando-se
o SPP, e o método de geração de colunas. Especificou-se a modelagem utilizada tanto no problema mestre quanto no subproblema.
Neste capitulo é apresentados métodos de solução para o problema mestre e o subproblema e a interação entre eles.

%solv_subp\begin{figure}[!htb]
{
    \centering
    \includegraphics[width=1\linewidth]{../figuras/flowchart.pdf}
    \captionof{figure}{Funcionamento de geração de colunas, adaptado de~\cite{dos2008metodo}}
    \label{flowchart}
}
%\end{figure}

Na Figura~\ref{flowchart} tem-se um fluxograma com as etapas de solução do CSP utilizando-se geração de colunas.
O processo de resolver o problema mestre (SPP) é apresentado na seção~\ref{solv_pmaster}. Para a solução do subproblema
analisou-se alguns métodos presentes na literatura e a seguir discutidos e são apresentados na seção~\ref{solv_subp}.

\section{Solução do Problema Mestre}
\label{solv_pmaster}

A solução de um problema mestre dá-se em 3 etapas (1, 2 e 3), conforme a Figura~\ref{flowchart},
que são executadas sequencialmente e uma etapa inicial (etapa 0) que é executada
uma única vez no inicio do procedimento. A etapa inicial (etapa zero) consiste em criar um conjunto de colunas que seja
factível para o problema mestre. Estas jornadas podem ser geradas aleatoriamente ou através da execução de alguma
heurística. As demais etapas são executadas toda vez que desejar-se resolver o problema mestre.

A etapa 1 é executada toda vez no inicio da solução do problema mestre. Esta etapa consiste em atualizar o modelo inserindo
as novas jornadas obtidas ou da etapa 0 ou da solução do subproblema. A etapa 2 é a execução do SIMPLEX em cima do modelo.
A etapa 3 consiste no calculo dos preços duais associado as restrições do problema.

\section{Solução do Subproblema}

O processo de solução do subproblema ocorre em duas etapas, conforme a Figura~\ref{flowchart}:
Na primeira etapa dado os preços duais, uma ou mais colunas são geradas de modo heurístico; Na
segunda etapa, que ocorre sequencialmente quando não é possível encontrar uma solução heurística,
resolve-se o problema de modo exato.

A utilização de heurísticas no subproblema
tende a gerar colunas mais rapidamente do que quando resolvido de modo exato. Porém, considerando que as colunas obtidas
heuristicamente não são necessariamente a solução do subproblema, pode ser necessário gerar-se mais colunas do que na solução
completamente exata (no subproblema e no problema mestre). Segundo os resultado de~\cite{dos2008metodo}, a utilização
das heurísticas no subproblema diminuíram o tempo de execução.

A solução exata do subproblema deve ser encontrada no caso de não ser encontrado uma solução heurística para que
se garanta que a solução final do SPP é ótima. Portanto, o SPP é inicialmente processado com uma ou mais heurísticas,
e caso não encontre-se uma solução com custo reduzido negativo, então deve ser utilizada a solução exata. A solução
exata do subproblema pode ser modelada como um caminho mínimo com restrições via PLI, conforme visto na seção~\ref{sec_subp}.
Este problema de PLI é resolvido utilizando-se o método de \textit{Branch and Cut}.

\subsection{Solução Heurística}
\label{solv_subp}

Nesta seção ão apresentados diversas heurísticas e meta-heurísticas encontradas na literatura e capazes de
serem utilizadas para resolver-se o subproblema. Como objetivo final do trabalho, deseja-se avalia-las e
incorporar uma ou mais heurísticas para acelerar o processo de solução do CSP.

\subsubsection{Busca Gulosa Baseada em Relaxação Linear}

Uma heurística simples para resolver o subproblema consiste em resolver a relaxação linear do mesmo. Conforme visto
no capitulo~\ref{cap1}, de modo geral a relaxação linear não leva a solução ótima de um problema de PLI. No entanto,
para algumas instâncias de um problema de PLI, é possível que isto ocorra, fazendo com que alguns casos de um problema
difícil sejam resolvido rapidamente.

No caso de resolver-se a relaxação linear de um subproblema e obter-se uma solução inteira de custo reduzido negativo,
pode-se gerar uma nova jornada e inseri-la no problema mestre, conforme ilustrado na Figura~\ref{flowchart}
Caso a solução seja inteira e não possua custo reduzido negativo,
então o problema mestre já possui o conjunto ótimo de colunas. Por fim, se for obtido uma solução não inteira
de custo reduzido negativo, pode-se aplicar uma ou mais heurísticas de arredondamento para obter uma solução inteira.
Este tipo de heurística é utilizada e ~\cite{glpk} e~\cite{scip} e apresentam um ganho significativo em caso de sucesso
a um custo irrelevante em caso de falha

\subsubsection{Subida de Encosta}

O algoritmo de otimização baseado em subida de encosta consiste consiste em uma simples operação gulosa
que busca o máximo local. Uma solução inicial é gerada aleatoriamente e a cada passo é escolhido uma modificação
aleatória que melhora a função objetivo.

É conhecido que o algoritmo de subida de encosta apresenta um desempenho pobre quando comparado a meta-heurísticas
mais sofisticadas~\cite{mitchell1993will}. No entanto, a subida de encosta é uma das heurísticas existentes mais simples e é capaz de
gerar soluções muito rapidamente. Oferecendo assim uma vantagem caso consiga alcançar rapidamente uma solução para
o problema, e pouca desvantagem caso não consiga, já que o sem tempo de execução é relativamente pequeno.

Quando aplicado ao subproblema apresentado neste trabalho, uma possível abordagem consiste em selecionar uma tarefa
de modo aleatório e considerar todas as tarefas e a antecedem ou sucedem. Destas tarefas adjacentes escolhe-se
a que apresenta o menor aumento da função objetivo. A função objetivo consiste na soma do custo de transição entre
duas tarefas adjacentes subtraído do preço dual associado as tarefas cobertas por esta transição. O algoritmo de busca
de encosta pode operar enquanto for possível adicionar tarefas sem violar a restrição de duração da jornada. É possível
retornar a jornada de maior duração encontrada ou armazenar as soluções parciais e retorna-las ao problema mestre.

\subsubsection{\textit{Simulated Annealing} - Recozimento Simulado}

O processo de \textit{annealing} (recozimento) é utilizado na industria metalúrgica com a finalidade de tratar os metais de modo a obter
características desejáveis. Um metal é aquecido a uma determinada temperatura e é resfriado de modo controlado, com
o objetivo de permitir que os cristais de carbono do aço possam de alocar de modo apropriado.

A otimização de \textit{Simulated Annealing} baseia-se no processo de \textit{annealing} para resolver problemas
de otimização~\cite{kirkpatrick1983optimization,eglese1990simulated}. O algoritmo de \textit{Simulated Annealing}
possui um comportamento semelhante ao de subida de encosta, onde a melhor alteração é escolhida.
A diferença está no fato de que é possível escolher uma alteração que tenha um impacto negativo na solução. Isto permite
que o algoritmo escape de máximos locais e possa explorar melhor o espaço de busca.

O algoritmo de \textit{Simulated Annealing}recozimento simulado possui uma variável de controle que é temperatura. Esta possui um valor inicial e
final arbitrário e predefinido. A função da temperatura é decidir a probabilidade de uma ação prejudicial a função
objetivo seja executada. Para valores altos da temperatura, a chance de tomar-se uma ação prejudicial é alta. Ao passar
das iterações do algoritmo a temperatura diminui conforme uma função predeterminada, até chegar na temperatura final.
Em valores próximos da temperatura final, o algoritmo possui uma chance próxima de zero de permitir que seja tomado
uma ação que tenha um impacto negativo na função objetivo.

Desta forma, o algoritmo inicia tomando possíveis decisões que pioram a função objetivo,
e com o passar das iterações estas ações tornam-se mais raras. Com isto é possível
escapar de máximos locais na função objetiva. A severidade do impacto na função objetivo também é considerado
na decisão, onde impactos menores tem a maior chance de serem feitos enquanto que impactos maiores possuem uma
menor chance.

Diversas alterações são possíveis em uma jornada, algumas que serão consideradas neste trabalho estão descritas
a seguir:

\begin{description}[font=$\bullet$\scshape\bfseries,labelindent=1cm]
    \item[Adicionar nova tarefa:] É verificado se é possível adicionar uma nova tarefa ao inicio ou fim da jornada;
    \item[Remover uma ou mais tarefas:] Uma ou mais tarefas são removidas;
    \item[Substituir tarefas:] Verifica-se se é possível substituir uma ou mais jornadas;
\end{description}

É possível utilizar uma ou mais estratégias de alteração da solução e seleciona-las de modo aleatório. Pode-se ainda parar
o algoritmo assim que uma solução de custo negativo seja encontrada ou executar o algoritmo até que a temperatura chegue
a temperatura final predeterminada e retornar a melhor solução obtida. Pode-se ainda armazenar todas as soluções de
custo reduzido negativo encontradas e retorna-las ao problema mestre.

\subsubsection{Colônia de Formigas}

A otimização de colônia de formigas (ACO, \textit{ant colony optimization})~\cite{dorigo2003ant},
é uma meta-heurística bioinspirada no comportamento emergente em formigas durante o processo de
coleta de alimento para a sua colônia. Uma formiga, ao iniciar a exploração de busca do
alimento, anda de forma aleatória e deixa um rastro de feromônio. Outras formigas ao fazer
a busca, executam o mesmo processo, porém, elas são atraídas pelo feromônio e possuem uma chance de seguir o rastro
previamente depositado. O feromônio naturalmente evapora, fazendo com que caminhos pouco utilizados evaporem e os
caminhos mais utilizados permaneçam.

Este comportamento é simulado computacionalmente e pode ser utilizado para resolver diversos problemas de otimização
combinatória~\cite{dorigo2005ant}. O algoritmo implementa um sistema multiagente (cada formiga é considerada um agente) onde existe
um comportamento emergente no coletivo dos agentes.  Problemas envolvendo grafos são facilmente resolvidos via
ACO e consistem em um exemplo clássico de aplicação.

Para resolver o subproblema, os agentes são todos posicionados no nó inicial e movem aleatoriamente depositando
feromônios. Quando o agente chega no nó final, ele é motivo para o nó inicial e o processo continua. Após a primeira
leva de agentes, o sistema tera rastro de feromônios que irá influenciar o comportamento dos próximos agentes.
Nas demais iterações, os agentes utilizando um mecanismo estocástico de decisão, onde existe uma tendencia
de seguir caminhos com maior concentração de feromônios. A cada iteração a concentração de feromônio é diminuída,
com o objetivo de eliminar caminhos pouco utilizados. Após um número predefinido de iterações, é possível extrair
o caminho de menor custo reduzido.

A ACO foi utilizada em diversos trabalhos recentes, aplicadas diretamente ao CSP~\cite{deng2011ant,lo2007using},
onde autores modelam o CSP como uma instância do \textit{traveling salesman problem} (TSP). O ACO pode ser
aplicado diretamente ao problema do caminho mínimo e suas variantes~\cite{ghoseiri2010ant,dorigo1997ant}.
E considerando a natureza do subproblema, o ACO pode ser aplicado diretamente~\cite{dorigo2006ant}.

\subsubsection{Busca Tabu}

A busca tabu é uma meta-heurística baseada na subida de encosta, onde uma modificação é aplicada sucessivamente
a uma solução, de modo guloso~\cite{glover1989tabu,glover1990tabu}. Para evitar ficar preso em máximos locais,
o algoritmo permite fazer uma modificação prejudicial para a função objetivo caso não seja
possível melhora-la. Quando isto ocorre, é criado uma regra que proíbe voltar para aquele estado.
Esta regra expira após um tempo predefinido.

Um modo de aplicar a busca tabu na solução do subproblema consiste em gerar uma solução inicial factível e trocar
uma tarefa por outra, sempre que isto melhorar a função objetivo. Caso não seja possível, deve-se então
marcar este estado como proibido e a trocar uma tarefa aleatória por outra. Este procedimento pode ser
executado por uma quantidade predefinida de passos ou até que uma solução de custo reduzido negativo
seja encontrada. No caso de executar o algoritmo por uma quantidade predefinida de passos, pode-se retornar
ao fim a melhor solução encontrada, ou retornar o conjunto de todas as soluções de custo reduzido negativo.

%\chapter{Resultados parciais}

%Do ré mi fá sol la si.

\section{Utilização das Heurísticas e Meta Heurísticas}

A proposta deste trabalho baseia-se no trabalho de~\cite{dos2008metodo}, onde utilizou-se o procedimento de
geração de colunas juntamente com duas meta heurísticas para resolver o CSP, onde o autor utilizou as meta heurísticas
GRASP~\cite{feo1995greedy} e algoritmo genético~\cite{gen1997genetic}. Tem-se como objetivo implementar
outras (meta) heurísticas com o objetivo de melhorar o procedimento de geração de colunas. Na Figura~\ref{flowchart}
tem-se um fluxograma que apresenta o funcionamento da geração de colunas. Os blocos de fundo cinza e contorno pontilhado
correspondem as etapas que são abordadas neste trabalho.

%solv_subp\begin{figure}[!htb]
%{
    %\centering
    %\includegraphics[width=1\linewidth]{../figuras/flowchart_wip.pdf}
    %\captionof{figure}{Funcionamento de geração de coluna}
    %\label{flowchart_wip}
%}
%\end{figure}

O bloco correspondente a geração das colunas inciais corresponde a um fator importante no processo de geração de colunas,
tendo em vista que os primeiros passos do método retiram a informação dual diretamente do conjunto inicial de colunas. Portanto,
deseja-se utilizar uma heurísticas para gerar um conjunto inicial de colunas. O procedimento de resolver o subproblema de
modo heurístico consiste na principal contribuição deste trabalho, onde o objetivo é identificar o desempenho de algumas
heurísticas presentes na literatura quando aplicadas a solução do subproblema e do CSP.

\chapter{Experimentos Computacionais e Análise}

O método proposto foi implementado utilizando-se as linguagens de programação C e C++. Utilizou-se o IBM ILOG CPLEX Optimizer~\cite{cplex} como
solver para os modelos de programação linear e programação linear inteira. A implementação do \textit{Branch and Price} foi escrita como um
\textit{plugin} para SCIP~\cite{MaherFischerGallyetal}. Todos os testes foram realizados em uma máquina com processador
Intel\textsuperscript{\textregistered} i7 Core\texttrademark~i7-4770 operando a 3.9 GHz, com 16 Gigabytes de RAM e rodando
um sistema operacional GNU/Linux com kernel $4.8.10$.

As instâncias \textit{benchmark} utilizadas para avaliar o método proposto foram retiradas biblioteca da \textit{OR-Library}~\cite{beasley1990or}. Os nomes utilizados para identificar as instâncias,
por exemplo, \textbf{csp100\_42}, representa um problema onde existem 100 tarefas a serem cobertas utilizando-se exatamente 44 jornadas. Todas as instâncias
possuem um tempo de jornada limitado a 480 minutos. Mais detalhes sobre as instâncias utilizadas podem ser encontrados em~\cite{beasley1996tree}.

Para o primeiro cenário de testes (meta heurísticas independentes), os tempos utilizados para resolver cada uma das instâncias, assim como as informações
sobre as meta heurísticas utilizadas estão contidas nas tabelas~\ref{tab_time_sep_hc} e~\ref{tab_time_sep_aco}.
Cada tabela agrega os resultados dos testes para duas heurísticas
que foram executadas de modo independente.  A coluna \textbf{Tempo} contém o tempo total de execução para resolver a instância. A coluna \textbf{Total}
contém o total de colunas geradas durante o processo de solução quando utilizada em conjunto com outra heurística (destacada na coluna ao lado).
A coluna \textbf{Heuristíca} indica dentre o total de colunas geradas, quantas foram geradas a partir da heurística nomeada na coluna.

Por exemplo, o lado esquerdo da tabela~\ref{tab_time_sep_hc} em sua primeira linha, contém os resultados dos testes para a instância~\textbf{csp100\_44} resolvida
utilizando o \textbf{hill climbing}. A coluna tempo contém o tempo total de execução em segundos ($27.6711$), a coluna ``Total'' contém o total de colunas geradas
durante o processo de solução ($243$). Por fim a coluna ``Heurística'' contém o número de colunas geradas pela heurística ($102$).
A diferença entre as colunas ``Total'' e `'heurística'' corresponde ao número de colunas que foram geradas (de modo exato) pelo método de \textit{Branch and Bound}, para
a linha em questão têm-se $243 - 102$, que equivale a $141$. Ao lado direito da tabela têm-se as mesmas informações, porém da execução de outra meta heurística.

\begin{center}
%\begin{table}[! htbp]
{
    \centering
    %\caption{Tempo e colunas geradas}
    \captionof{table}{Tempo e colunas geradas para o \textit{hill climbing} e \textit{Simulated Annealing}}
    \label{tab_time_sep_hc}
    \begin{tabular}{|r | r r r} \hline
        & \multicolumn{3}{c|}{\textit{Hill Climbing}} \\ \hline
        nome        & Tempo (s) & Total & Heurística \\ \hline
        %csp50\_27   & 1.4646    & 58.0       & 23.6    \\ \hline
        %csp50\_28   & 1.2432    & 57.6       & 25.3    \\ \hline
        %csp50\_29   & 1.4122    & 60.0       & 20.3    \\ \hline
        csp100\_42  & 27.6711   & 243.0      & 102.0   \\ \hline
        csp100\_43  & 16.5789   & 227.0      & 102.0   \\ \hline
        csp100\_44  & 15.8095   & 225.0      & 102.0   \\ \hline
        csp150\_67  & 122.9611  & 349.0      & 140.0   \\ \hline
        csp150\_68  & 107.5191  & 347.0      & 140.0   \\ \hline
        csp150\_69  & 73.6804   & 352.0      & 142.0   \\ \hline
        csp200\_86  & 402.6408  & 571.0      & 249.0   \\ \hline
        csp200\_87  & 202.4217  & 520.0      & 250.0   \\ \hline
        csp200\_88  & 150.5260  & 507.0      & 252.0   \\ \hline
        csp250\_111 & 199.4931  & 655.0      & 360.0   \\ \hline
        csp250\_112 & 204.0749  & 671.0      & 359.0   \\ \hline
        csp250\_113 & 192.7779  & 665.0      & 361.0   \\ \hline
    \end{tabular}%
    %\caption{Tempo e colunas geradas}
    %\label{tab_time_sep_sa}
    \begin{tabular}{| r r r|} \hline
        \multicolumn{3}{c|}{\textit{Simulaed Annealing}} \\ \hline
        Tempo (s)  & Total & Heurística \\ \hline
           %1.3804  & 59.0       & 31.6   \\ \hline
           %1.3353  & 63.3       & 34.6   \\ \hline
            %0.9542 & 60.0       & 36.6   \\ \hline
          32.3331  & 251.6      & 34.6   \\ \hline
          27.5180  & 247.3      & 50.3   \\ \hline
          28.0785  & 241.0      & 45.6   \\ \hline
         167.7493  & 395.6      & 49.0   \\ \hline
         156.1783  & 384.6      & 60.6   \\ \hline
         152.7513  & 432.3      & 68.6   \\ \hline
         651.7173  & 643.0      & 90.0   \\ \hline
         524.5502  & 605.0      & 94.6   \\ \hline
         521.8145  & 601.3      & 92.0   \\ \hline
         949.2324  & 790.0      & 178.0   \\ \hline
         830.3431  & 758.0      & 150.0   \\ \hline
         957.6591  & 751.0      & 137.6   \\ \hline
    \end{tabular}
%\end{table}
}
\end{center}

No segundo cenário de testes as heurísticas foram executadas de modo encadeado antes de executar a solução exata para o subproblema (se necessário).
A utilização de todas as heurísticas de modo encadeado levou ao segundo melhor tempo, de modo geral.
Conforme as tabelas~\ref{tab_time_sep_hc},~\ref{tab_time_sep_aco} e~\ref{tab_time_sep_exact}, pode-se observar que a utilização da busca tabu
(tabela~\ref{tab_time_sep_aco}) apresentou o menor tempo de execução em todos os casos.
Analisando-se o desempenho quando compara-se o tempo de execução da busca tabu com o tempo de execução do método de geração de colunas puramente
exato, verifica-se que a diferença de tempo foi significativa, chegando a ser aproximadamente 18 vezes mais rápido para as instâncias \textbf{csp250}.
Para instâncias de tamanhos menores esta diferença é menor, chegando a cair para um fator de aproximadamente 3.5 vezes.


\begin{center}
%\begin{table}[! htbp]
{
    \centering
    \captionof{table}{Tempo e colunas geradas para ACO e busca tabu}
    \label{tab_time_sep_aco}
    \begin{tabular}{|r | r r r} \hline
        & \multicolumn{3}{c|}{\textit{Ant Colony Optimization}} \\ \hline
        nome        & Tempo (s) & Total & Heurística  \\ \hline
        %csp50\_27   & 2.2504    & 63.6    &  25.0  \\ \hline
        %csp50\_28   & 1.6567    & 60.6    &  26.0  \\ \hline
        %csp50\_29   & 1.8225    & 57.6    &  23.3  \\ \hline
        csp100\_42  & 37.0227   & 240.0   &  98.3  \\ \hline
        csp100\_43  & 32.2277   & 232.0   &  99.0  \\ \hline
        csp100\_44  & 33.5735   & 237.0   &  93.0  \\ \hline
        csp150\_67  & 177.5754  & 386.0   & 146.0  \\ \hline
        csp150\_68  & 175.6358  & 380.0   & 149.0  \\ \hline
        csp150\_69  & 166.3722  & 397.0   & 148.0  \\ \hline
        csp200\_86  & 748.1522  & 612.0   & 198.3  \\ \hline
        csp200\_87  & 582.0481  & 568.0   & 199.0  \\ \hline
        csp200\_88  & 584.5416  & 583.0   & 198.6  \\ \hline
        csp250\_111 & 1785.0666 & 747.0   & 245.0  \\ \hline
        csp250\_112 & 1898.2388 & 750.0   & 246.3  \\ \hline
        csp250\_113 & 1981.3187 & 742.0   & 247.6  \\ \hline
    \end{tabular}%
    %\caption{Tempo e colunas geradas}
    %\label{tab_time_sep_sa}
    \begin{tabular}{| r r r|} \hline
        \multicolumn{3}{c|}{Busca Tabu} \\ \hline
        Tempo (s) & Total & Heurística \\ \hline
        %1.1262  & 82.6   & 65.0    \\ \hline
        %0.6998  & 65.3   & 50.6    \\ \hline
        %1.1270  & 85.0   & 60.6    \\ \hline
        11.4404  & 368.3  & 321.6    \\ \hline
        5.6778   & 364.6  & 325.6    \\ \hline
        5.7029   & 364.6  & 321.3    \\ \hline
        47.4881  & 582.0  & 503.6    \\ \hline
        35.1768  & 600.0  & 518.3    \\ \hline
        37.5174  & 598.3  & 503.3    \\ \hline
        226.6417 & 960.0  & 793.6    \\ \hline
        97.9521  & 925.3  & 784.0    \\ \hline
        85.4223  & 923.6  & 777.0    \\ \hline
        128.6715 & 1193.3 & 1019.6    \\ \hline
        107.7587 & 1145.6 & 967.6    \\ \hline
        92.4310  & 1161.3 & 992.0    \\ \hline
    \end{tabular}
%\end{table}
}
\end{center}

As demais meta heurísticas implementadas também proporcionaram redução no tempo de solução dos problemas. Em alguns casos a diferença não foi
significativa, melhorando menos de 2\%, como foi o caso do ACO na instância \textbf{csp200\_87}. Não obstante, esta pequena melhoria indica
que mesmo que a meta heurística seja capaz de gerar poucas colunas e falhe nas demais interações, ela ainda contribui para a diminuição
do tempo de execução. Isto dá-se pelo tempo necessário para resolver o subproblema de modo exato que, segundo os resultados obtidos, demonstram que
mais de 90\% do tempo de execução é gasto resolvendo-se o subproblema de modo exato.
A tabela~\ref{tab_time_sep_exact} contém os dados para o cenário 2 (meta heurísticas encadeadas) e para o cenário 3 (sem meta heurísticas).


\begin{center}
%\begin{table}[! htbp]
{
    \centering
    \captionof{table}{Tempo e colunas geradas para o método puramente exato e com a utilização de todas as meta heurísticas}
    \label{tab_time_sep_exact}
    \begin{tabular}{|r | r r r} \hline
        & \multicolumn{2}{c|}{Método exato puro} \\ \hline
        nome        & Tempo (s) & Total \\ \hline
        %csp50\_27   &   13.4217 &  58.6      \\ \hline
        %csp50\_28   &   10.5705 &  55.0      \\ \hline
        %csp50\_29   &   10.2935 &  57.0      \\ \hline
        csp100\_42  &   73.8325 & 240.0      \\ \hline
        csp100\_43  &   34.6233 & 232.0      \\ \hline
        csp100\_44  &   36.0911 & 237.0      \\ \hline
        csp150\_67  &  190.9429 & 386.0      \\ \hline
        csp150\_68  &  189.1863 & 380.0      \\ \hline
        csp150\_69  &  178.1048 & 397.0      \\ \hline
        csp200\_86  &  829.8991 & 612.0      \\ \hline
        csp200\_87  &  590.8635 & 568.0      \\ \hline
        csp200\_88  &  593.6881 & 583.0      \\ \hline
        csp250\_111 & 1884.8217 & 747.0      \\ \hline
        csp250\_112 & 1872.2440 & 750.0      \\ \hline
        csp250\_113 & 1842.4232 & 742.0      \\ \hline
    \end{tabular}%
    %\caption{Tempo e colunas geradas}
    %\label{tab_time_sep_sa}
    \begin{tabular}{| r r r|} \hline
        \multicolumn{3}{c|}{Meta heurísticas encadeadas} \\ \hline
        Tempo (s) & Total & Heurística \\ \hline
        %0.7770    &  59.6      &  48.2      \\ \hline
        %0.7018    &  60.3      &  49.6      \\ \hline
        %0.4759    &  68.3      &  60.0      \\ \hline
        11.3554   & 351.3      & 324.3      \\ \hline
        6.3006    & 343.6      & 312.3      \\ \hline
        4.2294    & 334.6      & 310.3      \\ \hline
        39.8183   & 509.6      & 456.6      \\ \hline
        31.0726   & 490.3      & 447.6      \\ \hline
        36.4308   & 533.0      & 681.0      \\ \hline
        243.9982  & 811.3      & 707.3      \\ \hline
        102.1412  & 780.6      & 706.3      \\ \hline
        92.4814   & 775.6      & 702.0      \\ \hline
        148.7475  & 943.3      & 865.3      \\ \hline
        152.1997  & 940.0      & 850.7      \\ \hline
        133.7747  & 906.3      & 821.3      \\ \hline
    \end{tabular}
%\end{table}
}
\end{center}

A tabela~\ref{tab_hit} apresenta as taxas de acertos e erros para cada uma das heurísticas e para o método exato. A razão entre o número
de colunas geradas no total e número de colunas geradas pela heurística corresponde a taxa de acerto. Seja $t_a$ a taxa de acerto, define-se
a taxa de erro como sendo $1.0 - t_a$. A taxa de acerto indica o quão eficaz a heurística foi em encontrar novas colunas.
A tabela~\ref{tab_time} contém na coluna ``Tempo'' o tempo total médio em segundos gasto para resolver todas as instâncias com um número de tarefas variando de $50$ até $250$.
A coluna ``Fator desempenho'' contém a razão entre o tempo de solução com uma determinada meta heurística e o tempo de solução utilizando o método de geração de colunas puramente exato.

A busca tabu foi a heurística que mais gerou novas colunas, conforme pode ser constatado nas tabelas~\ref{tab_time_sep_hc},~\ref{tab_time_sep_aco} e~\ref{tab_time_sep_exact}.
Considerando o número total de colunas geradas, a taxa de acerto e o tempo gasto, pode-se concluir que gerar uma grande quantidade de colunas de custo reduzido próximo a zero
contribuiu significativamente para reduzir o tempo necessário para se alcançar a solução ótima.

\begin{center}
{
    \begin{minipage}{0.49\linewidth}
        \centering
        \captionof{table}{Razão de colunas geradas}
        \label{tab_hit}
        \begin{tabular}{| l | l | l |} \hline
            Heurística & Acerto              & Erro \\ \hline
            hc         & 0.477 & 0.523 \\ \hline
            sa         & 0.183 & 0.819 \\ \hline
            aco        & 0.354 & 0.646 \\ \hline
            tabu       & 0.849 & 0.151 \\ \hline
            todos      & 0.901 & 0.099 \\ \hline
            exact      & 1.000 & 0.000 \\ \hline
        \end{tabular}%
    \end{minipage}
    \begin{minipage}{0.49\linewidth}
        \centering
        \captionof{table}{Desempenho relativo dos métodos}
        \label{tab_time}
        \begin{tabular}{| l | l | l |} \hline
            Heurística & Tempo              & Fator desempenho \\ \hline
            hc         & 114.719 & 4.853 \\ \hline
            sa         & 333.573 & 1.669 \\ \hline
            aco        & 547.167 & 1.017 \\ \hline
            tabu       &  58.988 & 9.437 \\ \hline
            todos      &  66.966 & 8.313 \\ \hline
            exact      & 556.733 & 1.000 \\ \hline
        \end{tabular}
    \end{minipage}
}
\end{center}

A Figura~\ref{fig_convergencia} apresenta o comportamento (convergência) da função objetivo do problema mestre ao longo do tempo.
Apresenta-se as curvas de convergência do método de geração de colunas puro com o método utilizando as
meta heurísticas. Para todas as execuções utilizou-se a mesma solução inicial do problema mestre, que é construída a partir de uma
jornada capaz de cobrir todas as tarefas (esta jornada é descartada assim que uma nova solução factível é encontrada).
O eixo $x$ da Figura representa o tempo de execução e o $y$ o valor da função objetivo do problema mestre. Analisando-se a Figura~\ref{fig_convergencia}
observou-se que a busca tabu, as heurísticas encadeadas e o \textit{hill climbing} convergiram rapidamente, conforme a ordem citada.
O recozimento simulado, conforme os testes realizados, teve um desempenho mediano. O ACO e o método puramente exato tiveram suas
convergências muito próximas.

%\begin{figure}[htpb]
{
    \centering
    \includegraphics[scale=1, resolution=120]{../figuras/nice_web_plot.png}
    %\includegraphics[width=0.6\linewidth]{figuras/nice_web_plot.png}
    %\includegraphics[width=0.8\linewidth]{figuras/nice_web_plot.png}
    %\includegraphics{figuras/nice_web_plot.png}
    \captionof{figure}{Convergencia dos métodos}
    \label{fig_convergencia}
}
%\end{figure}

Conforme a tabela~\ref{tab_time}, pode-se identificar que a execução da busca tabu foi em média 9 (nove) vezes mais rápida que o procedimento puramente exato.
%que a busca tabu foi capaz de, na média, resolver as instâncias de teste mais de $9$ vezes mais rapidamente. Em segundo lugar esta a implementação
O segundo melhor desempenho constatado esta quando utiliza-se todas as heurísticas de modo encadeado.
Em terceiro lugar, o \textit{hill climbing} melhorou na média o tempo de execução em um
fator de aproximadamente $4.8$. As demais heurísticas apresentaram um fator de redução de $1.6$ e $1.017$, o que apesar de baixo
quando comparado com as demais meta heurísticas implementadas, ainda é capaz de oferecer uma vantagem significativa
sobre o método puramente exato.

Uma possível explicação para a superioridade do \textit{hill climbing} e da busca tabu dá-se pelo fato de que em ambas
as implementações não é possível gerar colunas infactíveis (que violam a restrição do tempo). Já no \textit{simulated annealing} e
no ACO, durante o processo de execução encontrou-se colunas infactíveis, diminuindo assim a eficiência das meta heurísticas.

%Um aspecto a considerar na investigação da eficiência das meta heurísticas é a sua convergência.

%Pode-se observar que o ACO teve um comportamento semelhante à solução puramente exata, a diferença esta no fato de que o método
%começou a convergir mais cedo. Para a busca tabu e o \textit{hill clibing} pode-se observar sua rápida convergência para solução
%ótima do problema. A utilização de todas as heurísticas no processo de solução iniciou sua convergência após a busca tabu, porém
%convergiu mais rapidamente.
